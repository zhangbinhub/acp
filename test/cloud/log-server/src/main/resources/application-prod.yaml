server:
  address: 127.0.0.1
  port: 8780
# ===============================
# = Log To File Config
# ===============================
logging:
  file:
    path: logs/log-server
    name: ${logging.file.path}/${spring.application.name}.log
  logback:
    rollingpolicy:
      max-file-size: 5MB
      max-history: 30
  level:
    com.alibaba.nacos.client.naming: warn
# ===============================
# = Spring Config
# ===============================
spring:
  cloud:
    nacos:
      discovery:
        ip: ${server.address}
    bus:
      id: ${spring.application.name}:${server.address}:${server.port}:v${info.version}:${spring.profiles.active}
    stream:
      default-binder: kafka
      kafka:
        binder:
          brokers: 127.0.0.1:9092
#      bindings:
#        log_output:
#          binder: kafka
#          consumer:
#            headerMode: raw
#          producer:
#            headerMode: raw
#          # topic
#          destination: test-log
#          group: log-server-group
#          content-type: application/json
#        # 与@StreamListener注解中的value一致，是绑定的渠道名
#        log_input:
#          binder: kafka
#          consumer:
#            headerMode: raw
#          producer:
#            headerMode: raw
#          # topic
#          destination: test-log
#          group: log-server-group
#          content-type: application/json
###### 多个 kafka 时配置
#      binders:
#        kafka1:
#          type: kafka
#          environment:
#            spring:
#              cloud:
#                stream:
#                  kafka:
#                    binder:
#                      brokers: name87:9094
#                      zkNodes: name85:2181,name86:2181,name87:2181/kafka0101
#        kafka2:
#          type: kafka
#          environment:
#            spring:
#              cloud:
#                stream:
#                  kafka:
#                    binder:
#                      brokers: name85:9094
#                      zkNodes: name85:2181,name86:2181,name87:2181/kafkatest0101